<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <title>Generative Models | GAN & VAE</title>
  <link rel="stylesheet" href="../css/styles.css">
  
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <script>
    window.addEventListener('load', () => {
      document.body.classList.add('loaded');
    });
  </script>
</head>

<body class="fade-body">
  <div class="top-buttons">
    <a href="../index.html" class="btn">回首頁</a>
  </div>

  <div class="container project-detail">
    <a href="../index.html" class="btn">← Back to Home</a>
    
    <h1>Generative Models</h1>
    <p class="subtitle">GAN (Generative Adversarial Networks) & VAE (Variational Autoencoders) 實作</p>

    <hr>

    <section>
      <h2>作業簡介</h2>
      <p>本專案分別實作了 <strong>VAE</strong> 與 <strong>GAN</strong> 兩種經典的生成模型。目標是從 CelebA 資料集中學習，最後生成出像樣的人像照片。</p>
    </section>

    <section>
      <h2>使用技術 / 環境</h2>
      <div class="tech-stack">
        <ul>
          <li><strong>Language:</strong> Python 3.9</li>
          <li><strong>Framework:</strong> PyTorch</li>
          <li><strong>Dataset:</strong> CelebA</li>
          <li><strong>Models:</strong> Convolutional VAE, Deep Convolutional GAN (DCGAN)</li>
          <li><strong>Techniques:</strong> Reparameterization Trick, Spectral Normalization</li>
        </ul>
      </div>
    </section>

    <section>
      <h2>方法介紹 (Methodology)</h2>
      
      <div class="method-block">
        <h3>1. VAE: Reparameterization Trick 與 ELBO</h3>
        <p>VAE 的目標是最大化 Evidence Lower Bound (ELBO)。為了讓從 Latent Space 取樣的過程可以進行 Backpropagation，實作中使用了 <strong>Reparameterization Trick</strong>，將隨機性轉移到 <strong>eps</strong>，並結合 Reconstruction Loss (MSE) 與 KL Divergence 來計算總 Loss。</p>
        <div class="code-box">
<pre><code># Reparameterization 實作
z_mean, z_logvar = netEnc(data)
std = torch.exp(0.5 * z_logvar)
eps = torch.randn_like(std)
z = z_mean + eps * std  # 讓梯度可回傳

# Loss 計算 (MSE + KL Divergence)
rec_loss = nn.MSELoss()(netDec(z), data)
kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())
loss = rec_loss + 0.0001 * kl_loss</code></pre>
        </div>
      </div>

      <div class="method-block">
        <h3>2. GAN: Minimax Game 與訓練穩定性</h3>
        <p>GAN 由 Generator (G) 與 Discriminator (D) 組成。為了避免訓練初期的 <strong>Gradient Vanishing</strong> 問題，我們採用了 Non-Saturating Loss 的實作方式：</p>
        
        <div class="code-comparison">
          <div class="code-column">
            <h4>Discriminator (D) 的目標</h4>
            <img src="../images/GAN_VAE/D_Loss.png" alt="D_Loss" class="method-img">
            <p>分辨真假，因此對於 Fake Data 會給予 Label 0 (Zero) 進行 BCELoss 訓練，並且要切斷 G 的梯度。</p>
            <div class="code-box">
<pre><code># D 想把 Fake 判斷為 0
fake_inputs = netGen(z)
d_fake, _ = netDis(fake_inputs.detach())
d_label = torch.zeros(..., 1)
d_fake_loss = nn.BCELoss()(d_fake, d_label)</code></pre>
            </div>
          </div>

          <div class="code-column">
            <h4>Generator (G) 的目標</h4>
            <img src="../images/GAN_VAE/G_loss.png" alt="G_Loss" class="method-img">
            <p>為了提供 G 更好的梯度，我們不最小化被識破的機率，而是<strong>最大化</strong>騙過 D 的機率 (Label 設為 1)。</p>
            <div class="code-box">
<pre><code># G 想讓 D 把 Fake 判斷為 1
d_fake, _ = netDis(fake_inputs)
d_label = torch.ones(..., 1)
g_loss = nn.BCELoss()(d_fake, d_label)</code></pre>
            </div>
          </div>
        </div>
      </div> 

      <div class="method-block">
        <h3>3. Discriminator 架構與 Spectral Normalization</h3>
        <p>為了滿足 Lipschitz Continuity，防止 GAN 訓練過程中的 Mode Collapse 或是梯度爆炸，我們在 Discriminator 的卷積層加上了 <code>spectral_norm</code>。同時，Forward 回傳了 <code>Logit</code> 與 <code>Prob</code> 以兼顧數值穩定性與直觀觀測。</p>
        <div class="code-box">
<pre><code>self.conv2 = nn.utils.spectral_norm(Conv2d(ch, ch*2, 5, stride=2))
# ...
d_logit = self.fc(x)                 # 用於 BCEWithLogitsLoss (較穩定)
d_prob = torch.sigmoid(d_logit)      # 用於觀測預測機率 (0~1)</code></pre>
        </div>
      </div>
    </section>

    <section>
      <h2>訓練技巧 (Training Tricks)</h2>
      <div class="trick-grid">
        <div class="trick-item">
          <h4>Detach 阻斷梯度流</h4>
          <p>在訓練 Discriminator 時，必須使用 <code>fake_inputs.detach()</code>。這可以確保 Backpropagation 只會更新 D 的權重，而不會錯誤地干擾到 Generator 的參數。</p>
        </div>
        <div class="trick-item">
          <h4>KL Loss Weight Tuning</h4>
          <p>在 VAE 中，若 KL Divergence 過強會導致 <strong>Posterior Collapse</strong> (模型忽略 Latent Code)。因此加上一個較小的權重 (如 0.0001)，迫使模型優先學好影像重建。</p>
        </div>
      </div>
    </section>

    <hr>

    <section>
      <h2>結果比對 (Results)</h2>
      
      <div class="row mb-4">
        <div class="col-12">
          <div class="chart-block">
            <h3>生成結果分析</h3>
            <div class="stats-box">
              <p><strong>VAE:</strong> 重建的影像較為平滑模糊，但 Latent Space 具有良好的連續性與插值特性。</p>
              <p><strong>GAN:</strong> 生成的影像細節較銳利、逼真，但在訓練過程中 Loss 的震盪較為劇烈，需要精細調參。</p>
            </div>
          </div>
        </div>
      </div>

      <div class="method-block">
        <h3 class="text-center mb-4">生成截圖 (GAN vs VAE)</h3>
        <div class="comparison-results">
          <div style="flex: 1; text-align: center;">
            <p><strong>VAE Result</strong></p>
            <img src="../images/GAN_VAE/VAE_result.jpg" alt="VAE Result" class="method-img" style="box-shadow: 0 4px 8px rgba(0,0,0,0.1); border-radius: 8px;">
          </div>
          <div style="flex: 1; text-align: center;">
            <p><strong>GAN Result</strong></p>
            <img src="../images/GAN_VAE/GAN_result.jpg" alt="GAN Result" class="method-img" style="box-shadow: 0 4px 8px rgba(0,0,0,0.1); border-radius: 8px;">
          </div>
        </div>
      </div>
    </section>

    <section class="resources">
      <h2>相關資源</h2>
      <p>點擊下方按鈕查看完整的 PyTorch 程式碼實作。</p>
      <a href="https://github.com/SSDViggo/ML_code" target="_blank" class="btn btn-github">View on GitHub</a>
    </section> 
  </div>

  <footer>
    <p>&copy; 2026 江宇綸 | Generative Models Report</p>
  </footer>

</body>
</html>